Ahoj! this is me starting my very indepth concretization learning of my 3+ years in imperative programming. I will be taking all measures to ensure that everything I write or adapt of code is 100% understood by me. 

The whys, whynots, hows and how not will be recorded.

This is my first project which is the transcedence project which we did as the final project at the 42 Prague programming school.

This final project is a full-stack SPA pong tournament gaming system that incorporates blockchain integration, AI opponents, remote and multiple players, real-time data management, dashboards, user authentication, GDPR compliance, and many more functionalities.

So let's dive in.

We decided not to build this website as a [microservice](#microservice), but rather as [monolitihic](#monolithic) architcture.
What is the difference between these two.

# monolithic architecture 
is the traditional way of web development or programming where the whole code base is a single unified unit or codebase, where all frontend, backend, business logic and data access are bundled together and run as a single service or process.

âš™ï¸ Example:

Imagine an e-commerce app where:

The product catalog, order management, user authentication, and payment processing are all built and deployed together as one large application (e.g., one .jar, .war, or single Docker image).


-------------------------------------------------------------------------------------------------------------------------------------------------------------------

# ğŸ§  Monolithic vs Microservice Architecture â€” Full Summary

## â“ Whatâ€™s the difference between Monolithic and Microservice Architecture?

### ğŸ§± **Monolithic Architecture**

**Definition:**
All parts of the application (frontend, backend, database logic, etc.) are combined into one unified codebase and run as a **single service or process**.

**Example:**
An e-commerce app where login, products, orders, and payments are all in one big program.

**âœ… Advantages**

* Simple to develop and deploy (good for small teams)
* Easier to test initially
* All code in one place

**âŒ Disadvantages**

* **Hard to scale:** must scale the entire app even if only one part needs it
* Tight coupling (a small change can break other parts)
* Difficult to adopt new tech or frameworks
* Longer deployment times
* Becomes slower and complex as it grows

---
# microservice
### ğŸ§© **Microservice Architecture**

**Definition:**
Breaks the application into multiple small, independent services, each handling a specific business function.
Each service runs on its **own process/server/container** and communicates with others via APIs (HTTP, gRPC, message queues).

**Example:**
An e-commerce system with:

* User Service ğŸ‘¤
* Product Service ğŸ›ï¸
* Checkout Service ğŸ’³
* Notification Service ğŸ“©

**âœ… Advantages**

* Independent deployment (update one service without redeploying all)
* Scale services individually
* Fault isolation (if one fails, others continue)
* Use different technologies for different services
* Great for large/distributed teams

**âŒ Disadvantages**

* More complex setup (DevOps, monitoring, CI/CD)
* Network communication overhead
* Harder to test integration between services
* Data consistency challenges

---

### âš–ï¸ **Quick Comparison Table**

| Feature              | Monolithic              | Microservices             |
| -------------------- | ----------------------- | ------------------------- |
| **Structure**        | Single unified codebase | Many independent services |
| **Deployment**       | One package             | Per service               |
| **Scaling**          | Scale whole app         | Scale individual service  |
| **Technology stack** | Single tech             | Mixed tech allowed        |
| **Fault tolerance**  | One failure affects all | Isolated failures         |
| **Communication**    | Internal function calls | API or message queues     |
| **Best for**         | Small/simple apps       | Large, scalable systems   |

---

## â“ What does â€œhard to scaleâ€ mean in Monolithic Architecture?

### âš™ï¸ Explanation

In a **monolith**, all parts (login, checkout, reports, etc.) run together as one process.
You **canâ€™t scale only one part** thatâ€™s under heavy load â€” you must scale the entire app.

### ğŸ’¡ Example

* During Black Friday, only **checkout** gets heavy traffic.
* You canâ€™t add more resources to just checkout.
* You must duplicate the whole app (checkout + login + catalog + reports), wasting CPU and memory.

**Result:** Inefficient scaling, higher cost, and wasted resources.

### ğŸ§® Example Table

| Component | Normal Load | Peak Load | Scaling Need |
| --------- | ----------- | --------- | ------------ |
| Home Page | 1x          | 1x        | No           |
| Checkout  | 1x          | 10x       | Yes          |
| Reports   | 1x          | 1x        | No           |

In a monolith, to handle checkout load, you must **scale everything 10x**.
In microservices, you scale **only Checkout Service**.

## â“ How does scaling actually work?

### ğŸ§  Meaning

**Scaling** = increasing system capacity to handle more users or data without slowing down.
Not about checking inputs faster â€” itâ€™s about **adding computing resources**.

---

### 1ï¸âƒ£ **Vertical Scaling (Scaling Up)**

You make one server stronger.

* Add CPU, memory, faster disks.
* Like upgrading one computer.

**Example:**
1 server â†’ bigger server with more RAM.

**Limit:** Physical and expensive limits.

---

### 2ï¸âƒ£ **Horizontal Scaling (Scaling Out)**

You add more servers/instances to share the workload.

* Use a **load balancer** to distribute user requests evenly.

**Example:**

```text
User â†’ Load Balancer â†’ Server 1
User â†’ Load Balancer â†’ Server 2
User â†’ Load Balancer â†’ Server 3
```

**Result:** Same app code, more copies working in parallel.

---

### âš–ï¸ Comparison

| Type                   | Description      | Example           | Limit                |
| ---------------------- | ---------------- | ----------------- | -------------------- |
| **Vertical Scaling**   | Stronger machine | Add more RAM, CPU | Expensive, limited   |
| **Horizontal Scaling** | More machines    | Add more servers  | Needs load balancing |

---

## â“ So in microservices, each service has its own server?

âœ… **Exactly.**
Each microservice runs on its own **server, container, or process** and can be **scaled independently**.

### Example

| Service              | Function     | Normal Load | Peak Load | Scaling Action |
| -------------------- | ------------ | ----------- | --------- | -------------- |
| User Service         | Login/signup | 1x          | 2x        | +1 instance    |
| Product Service      | Catalog      | 1x          | 3x        | +2 instances   |
| Checkout Service     | Payments     | 1x          | 10x       | +9 instances   |
| Notification Service | Email/SMS    | 1x          | 5x        | +4 instances   |

Only scale whatâ€™s under pressure â€” not the entire app.

### ğŸ§© How it works

* Each service runs independently.
* Load balancer detects high traffic â†’ adds more instances of that service.
* Others remain unchanged.
* After load drops â†’ auto-scale down.

---

## ğŸš€ In Summary

| Aspect             | Monolithic        | Microservices           |
| ------------------ | ----------------- | ----------------------- |
| **Deployment**     | Single unit       | Many small units        |
| **Scaling**        | Entire app        | Per service             |
| **Resource usage** | Inefficient       | Efficient               |
| **Failure impact** | Whole app         | Isolated                |
| **Flexibility**    | Harder            | Easier                  |
| **When to use**    | Small/simple apps | Large, evolving systems |

---

### ğŸ§¾ Final Takeaway

* **Monolithic** â†’ simple but rigid and hard to scale efficiently.
* **Microservices** â†’ modular, flexible, and independently scalable but more complex to manage.

------------------------------------------------------------------------------------------------------------------------------------------------------------------

Now we understand the difference between microservice and monolithic architecture.

The subject requested that we build the system as a Single Page Application [SPA](#SPA).

# SPA
An SPA is a front-end architecture pattern, not a full system architecture.
It means the entire web app runs mostly in the browser â€” loading one HTML page and dynamically updating content via JavaScript (using frameworks like React, Angular, or Vue).

So when you navigate between pages, the browser doesnâ€™t reload everything â€” it just changes parts of the page.
That makes it fast and smooth.

# The frontend:
The frontend app is a TypeScript + Vite single-page application organized around small, focused UI components and a clear separation between UI, game logic, and backend-communication services services. 

It means, once the project is started with a #makefile, it must install the node modules for these languages or codebase to work.

# The backend
The backend is a Fastify-based Node.js HTTP API (ES module) that uses a small, modular service pattern: server.js wires plugins, routes, and Swagger; db.js initializes a local SQLite database and exposes it via Fastify decoration; route modules in routes/ register endpoints (public and protected) which call controller functions in controllers/ to implement business logic (auth, friends, leaderboard, tetris, tournaments, user profiles). Authentication/session handling is cookie-based: sessions are stored in the SQLite sessions table, validated by a reusable authPlugin Fastify plugin that decorates requests with userId. File uploads (avatars) are handled with Fastify multipart + static file serving for avatars. Input contracts are expressed using JSON schemas under schemas/, and the server exposes OpenAPI/Swagger UI. The code centralizes DB helpers and utilities in utils/ and uses server-side GDPR/consent cookies and other cross-cutting concerns as cookies. Overall itâ€™s a single-process, low-dependency backend focused on small modules, SQLite persistence, and HTTP (with room for real-time match flows implemented via DB-driven tokens/queues).

--- Database SQLite
--- Fastify (server files)
--- Swagger.




### â“2. What does â€œhard to scaleâ€ mean in monolithic architecture?

**Answer:**
In a monolith, all features share one deployment.
If one part (e.g., checkout) needs more power, you must **scale the whole app**, wasting resources.
âœ… *In microservices, you scale only the part that needs it.*

---

### â“3. How does **scaling** work?

**Answer:**
Scaling means increasing capacity to handle more users or data.

* **Vertical scaling:** Add more CPU/RAM to one server.
* **Horizontal scaling:** Add more servers/instances and use a load balancer to share the work.
  âœ… *Scaling adds computing power â€” itâ€™s not about checking inputs faster.*

---

### â“4. In microservices, do you have a server for each service?

**Answer:**
Yes. Each microservice runs in its **own server or container**, with its own logic and database.
When one part (e.g., payments) needs more resources, you **scale just that service**.
âœ… *Independent scaling = better performance and efficiency.*

---

### â“5. So is this design (nginx + backend + frontend) a microservice?

**Answer:**
Not fully. Itâ€™s a **modular, 3-tier containerized architecture**, not true microservices.

* You have **frontend**, **backend**, and **nginx** as separate containers.
* But thereâ€™s still **one backend service**, so itâ€™s not yet microservice-level.
  âœ… *Itâ€™s microservice-like but technically a structured monolith.*

---

### â“6. Whatâ€™s the difference between **Next.js**, **Node.js**, and **Nginx**?

**Answer:**

| Tool        | Role                                                                            |
| ----------- | ------------------------------------------------------------------------------- |
| **Node.js** | JavaScript runtime that runs backend logic (APIs, servers).                     |
| **Next.js** | Web framework built *on top* of Node.js for full-stack React apps (SSR + APIs). |
| **Nginx**   | Web server / reverse proxy that serves static files and routes traffic.         |

âœ… *They complement each other â€” Node runs code, Next builds apps, Nginx handles traffic.*

---

### â“7. Does **Nginx** run on **Node.js**, or vice versa?

**Answer:**
Neither.
They run **side by side**, but **Nginx sits in front of Node.js**:

* Nginx listens to users on port 80/443
* It **forwards** (proxies) requests to Node.js (e.g., port 3000)
  âœ… *Nginx = gateway; Node.js = backend app.*

---

### â“8. Does **Nginx** listen to **Node.js**?

**Answer:**
âŒ No.
**Node.js listens** for incoming requests.
**Nginx** listens to users and **forwards** their requests to Node.js.
âœ… *Node.js is the listener; Nginx is the forwarder.*

---

### â“9. So Node listens to requests from clients coming through Nginx, and serves the requested resource through Nginx?

**Answer:**
âœ… Exactly.

1. The **client** sends a request to **Nginx**.
2. **Nginx** forwards it to **Node.js**.
3. **Node.js** processes and sends the response back to **Nginx**.
4. **Nginx** returns it to the **client**.
   âœ… *Nginx handles traffic; Node.js handles logic.*

---

### â“10. If some HTML files need to be pulled or modified and itâ€™s not happening on the frontend, does it happen in Node.js or Nginx?

**Answer:**

* **Static HTML** (unchanging) â†’ handled by **Nginx** directly.
* **Dynamic HTML** (changes with user data or logic) â†’ generated by **Node.js**.
  âœ… *Nginx serves static files; Node.js creates or modifies dynamic ones.*

---

### â“11. Can **Node.js** serve files without **Nginx**?

**Answer:**
âœ… Yes, Node.js can serve files on its own â€” using `http`, `fs`, or frameworks like Express.
But âš ï¸ in production, **Nginx is preferred** because itâ€™s faster, safer, and optimized for static file delivery.
âœ… *Use Node.js alone for development; add Nginx for performance in production.*

---

### â“12. What are the alternatives to **Node.js** and **Nginx**?

**Answer:**
ğŸ§© **Alternatives to Node.js (backend runtimes):**

* Python (Django, Flask, FastAPI)
* Go (Gin, Fiber)
* Java (Spring Boot)
* .NET (C# / ASP.NET Core)
* Rust (Actix, Rocket)
* PHP (Laravel, Symfony)
* Ruby (Rails)
* Elixir (Phoenix)
* Deno / Bun (modern JS runtimes)

ğŸ§± **Alternatives to Nginx (web server / proxy):**

* Apache HTTP Server
* Caddy (auto HTTPS)
* HAProxy (load balancer)
* Traefik (Docker/Kubernetes)
* Envoy Proxy (service mesh)
* Cloudflare / Fastly (CDN edge servers)

âœ… *Node.js alternatives = backend runtimes; Nginx alternatives = reverse proxies / web servers.*




> **Node.js** is the **runtime environment** â€” it runs JavaScript on the server.
> **Fastify** is a **web framework built *on top* of Node.js** that helps you create APIs faster, cleaner, and safer.

âœ… So theyâ€™re **not alternatives** â€” they **work together**.
Fastify **uses Node.js under the hood**.

---

## âš™ï¸ Think of it this way

| Concept                 | Example                               | What it means                                      |
| ----------------------- | ------------------------------------- | -------------------------------------------------- |
| **Runtime / Engine**    | ğŸ§  **Node.js**                        | Executes JavaScript code on the server             |
| **Framework / Library** | ğŸ§© **Fastify**, Express, NestJS, etc. | Uses Node.js to simplify HTTP handling and routing |
| **Your App**            | ğŸ§° Your `server.js`, routes, plugins  | Built using a framework running on Node.js         |

---

### ğŸ” Analogy

| Example      | Analogy                                                                       |
| ------------ | ----------------------------------------------------------------------------- |
| **Node.js**  | The **car engine** â€” it makes things run.                                     |
| **Fastify**  | The **car dashboard + controls** â€” makes driving easier and more comfortable. |
| **Your API** | You driving to your destination. ğŸš—ğŸ’¨                                         |

So â€” Node.js provides the *power*; Fastify provides the *structure*.

---

## ğŸ§© Without Fastify

You could build an HTTP server directly with **Nodeâ€™s core module**:

```js
import http from 'http';

const server = http.createServer((req, res) => {
	res.writeHead(200, { 'Content-Type': 'text/plain' });
	res.end('Hello World');
});

server.listen(3000);
```

âœ… Works fine â€” but:

* You have to manually handle routes (`/login`, `/users`, etc.)
* No built-in JSON parsing, middleware, or plugins

---

## ğŸ§© With Fastify

Fastify *uses Nodeâ€™s `http` module under the hood* â€” it just adds higher-level features:

```js
import Fastify from 'fastify';

const fastify = Fastify();

fastify.get('/hello', async (req, reply) => {
	return { msg: 'Hello from Fastify!' };
});

fastify.listen({ port: 3000 });
```

âœ… You now get:

* Routing (`fastify.get`, `fastify.post`)
* Automatic JSON handling
* Plugin system (for auth, logging, etc.)
* Much faster performance and safety

So your app still **runs on Node.js**, but **through Fastify**.

---



Fastify (and Express) are frameworks built on top of Node.js, not exactly â€œplugins,â€ but they work like high-level helpers that make configuring Nodeâ€™s web server easy and structured.

Browser â”€â–º Nginx â”€â–º Node.js (http module)
                    â””â”€â”€â–º Fastify / Express framework
                              â””â”€â”€â–º Your API logic (routes, DB calls)



*************************************************************************************************************************

***if i am not using docker at all, and I will just npm run dev, do i need nginx?***

> **No â€” you do *not* need Nginx** if youâ€™re just running your Fastify app locally (using `npm run dev`) or even deploying it as a standalone Node.js app on a server.

But letâ€™s unpack *why* â€” and also *when* Nginx *does* become useful â€” so you really understand the decision. ğŸ‘‡

---

## ğŸ§  What Nginx actually does

Nginx (pronounced *â€œengine-xâ€*) is a **web server and reverse proxy**.
Itâ€™s not part of Node or Fastify itself â€” it sits **in front** of your backend to help with:

| Feature                      | Description                                                                                              |
| ---------------------------- | -------------------------------------------------------------------------------------------------------- |
| **Reverse proxying**         | Routes traffic from the internet to your Node/Fastify app (often running on an internal port, like 3000) |
| **Load balancing**           | Distributes traffic across multiple Node processes or servers                                            |
| **Static file serving**      | Efficiently serves images, JS, CSS, etc. (faster than Node)                                              |
| **SSL/TLS termination**      | Handles HTTPS certificates (so your app only deals with HTTP internally)                                 |
| **Caching & compression**    | Caches static assets or compresses responses for speed                                                   |
| **Security / Rate limiting** | Blocks bad requests, limits rate, hides internal ports                                                   |

So itâ€™s like a **gatekeeper** in front of your Fastify server.

---

## ğŸ§© Case 1 â€” Local development (`npm run dev`)

You definitely **donâ€™t need Nginx** here.

When you run:

```bash
npm run dev
```

and your Fastify app listens on `http://localhost:3000`,
you can access it directly in your browser or from your frontend (`fetch("http://localhost:3000/â€¦")`).

Thereâ€™s no extra layer needed â€” Fastify can:
âœ… serve static files (via `@fastify/static`)
âœ… handle CORS
âœ… run HTTPS locally if you configure it

So Nginx adds **no benefit** in development â€” it would just complicate things.

---

## ğŸ§© Case 2 â€” Simple production server (single app)

Even in production, if you have **just one Node.js app** and youâ€™re fine exposing it directly on port 80 or 443,
you can still skip Nginx.

Example:

```bash
node server.js
```

Then:

* use **PM2** or **systemd** to keep it alive and restart on crash
* optionally use **Certbot + Node HTTPS** if you need HTTPS directly in Fastify

Fastify can easily serve everything itself:

```js
fastify.register(import('@fastify/static'), { root: 'public' });
fastify.get('/api', ...);
```

So itâ€™s totally fine to go â€œFastify only.â€

---

## ğŸ§© Case 3 â€” When Nginx *is* recommended

Use Nginx when:

| Situation                                                                | Why Nginx helps                                                    |
| ------------------------------------------------------------------------ | ------------------------------------------------------------------ |
| ğŸ§  You deploy **multiple apps** (e.g., Fastify API + React build)        | Nginx can route `/api/*` to Fastify and `/` to your frontend files |
| ğŸ” You need **HTTPS (SSL)**                                              | Nginx easily handles SSL certs (via Letâ€™s Encrypt)                 |
| âš¡ You want **caching / compression / CDN-like performance**              | Nginx serves static assets much faster than Node                   |
| ğŸ§© You want to **load balance** multiple Node workers                    | Nginx distributes requests automatically                           |
| ğŸ›¡ You need **rate limiting / security headers**                         | Easier to add rules before traffic hits Node                       |
| ğŸ§± Youâ€™re inside a Docker or cloud setup (e.g., EC2, DigitalOcean, etc.) | Nginx acts as the front-facing web server                          |

So basically:

> ğŸ‘‰ If your app will be **publicly accessible on the web**, Nginx is *nice-to-have* (for SSL + routing).
> ğŸ‘‰ If your app is **local, internal, or single service**, you can skip it safely.

---

## ğŸ§­ 4. How your setup looks *without* Nginx

For your case (just `npm run dev` and Fastify):

```
Frontend (React, Vite) â†’ http://localhost:5173
Backend (Fastify) â†’ http://localhost:3000
```

Frontend calls backend directly using `fetch()` with CORS enabled:

```js
await fetch("http://localhost:3000/api/items");
```

Your Fastify already handles:

* CORS âœ…
* Cookies âœ…
* Static files âœ…
* File uploads âœ…

So everything works fine.

---

## âš™ï¸ Optional: When you move to production later

If you deploy your app to:

* a VPS (like DigitalOcean, Linode)
* or a small VM
* or you use PM2 to keep Node alive

Then you *might* later add Nginx with a config like:

```nginx
server {
    listen 80;
    server_name myapp.com;

    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
    }
}
```

Thatâ€™s when it acts as your front-door â€” forwarding traffic to Fastify.

---

## âœ… Summary

| Environment                        | Need Nginx? | Why                                        |
| ---------------------------------- | ----------- | ------------------------------------------ |
| Local dev (`npm run dev`)          | âŒ No        | Fastify can serve everything directly      |
| Small personal or internal server  | âŒ No        | Node can handle it                         |
| Public-facing production server    | âš ï¸ Optional | Use for SSL, reverse proxy, static caching |
| Multiple services / load balancing | âœ… Yes       | Needed for routing & proxying              |

---

### ğŸ’¬ In one sentence:

> You only need Nginx when your Fastify app is **serving the public web or running multiple services** â€” for local dev or single-server apps, Fastify alone is perfectly enough.



*************************************************************************************************************************


Now we start


*************************************************************************************************************************


what should be done now, is to create three folders, frontend, backend and nginx(server) folders.

```
project-root/
â”œâ”€â”€ frontend/
â”œâ”€â”€ backend/
â””â”€â”€ nginx/
```


*************************************************************************************************************************

Then lets initiialize the node modules in the root of our project

```bash
npm init
or
npm init -y to yes all the questions
```


*************************************************************************************************************************

## ğŸ§  Short Answer

| File                    | Purpose                                                                    |
| ----------------------- | -------------------------------------------------------------------------- |
| **`package.json`**      | Describes your project â€” name, version, dependencies (the â€œwhatâ€)          |
| **`package-lock.json`** | Locks the exact versions of those dependencies (the â€œwhich ones, exactlyâ€) |

So in simple terms:

> ğŸŸ¢ **`package.json`** = â€œWhat packages do I need?â€
> ğŸ”’ **`package-lock.json`** = â€œWhich exact versions were installed?â€

---

## ğŸ§± 1ï¸âƒ£ `package.json` â€” The Project Manifest

This is your projectâ€™s **blueprint**.

It defines:

* The project name, description, version
* The dependencies your app *requires*
* Optional metadata (scripts, author, license, etc.)

Example:

```json
{
  "name": "my-app",
  "version": "1.0.0",
  "description": "Learning Node",
  "main": "index.js",
  "scripts": {
    "start": "node index.js"
  },
  "dependencies": {
    "express": "^4.18.0",
    "mongoose": "^7.0.0"
  }
}
```

### ğŸ’¡ Notice the `^` symbol:

* `"^4.18.0"` means â€œinstall **4.18.0 or any newer minor/patch version** (e.g. 4.19.1)â€
* So `package.json` allows **some flexibility** â€” it doesnâ€™t lock you to one exact version.

âœ… Think of it as your â€œrecipeâ€ or shopping list.

---

## ğŸ”’ 2ï¸âƒ£ `package-lock.json` â€” The Exact Snapshot

This file is automatically created (or updated) when you run:

```bash
npm install
```

It records:

* The **exact versions** of every dependency and sub-dependency installed.
* The **npm registry URLs** where they came from.
* The **integrity hashes** to ensure they havenâ€™t been tampered with.

Example snippet:

```json
{
  "name": "my-app",
  "lockfileVersion": 3,
  "requires": true,
  "packages": {
    "": {
      "dependencies": {
        "express": "^4.18.0"
      }
    },
    "node_modules/express": {
      "version": "4.18.2",
      "resolved": "https://registry.npmjs.org/express/-/express-4.18.2.tgz",
      "integrity": "sha512-xxyyzz..."
    }
  }
}
```





*****************************************************************************************

## ğŸ§  1ï¸âƒ£ What `npm create vite@latest .` actually does

That command **sets up the full frontend structure for you** automatically.

When you run it (in an empty folder), it:

1. Asks which framework you want (e.g. Vanilla, React, Vue, Svelte, etc.)
2. Creates all the starter files for that framework:

   ```
   index.html
   main.js
   vite.config.js
   package.json
   ```
3. Installs basic dependencies needed for Vite to run the dev server.

âœ… So you **donâ€™t need to create HTML or CSS files manually first** â€”
Vite gives you a ready-made starting point.

---

## âš™ï¸ 2ï¸âƒ£ What happens if you already have files

If your `frontend` folder already has files (like `index.html` or `style.css`) and you run:

```bash
npm create vite@latest .
```

then:

* Vite might **warn you** that the directory isnâ€™t empty:

  ```
  âœ– Current directory is not empty. Continue? (y/N)
  ```
* If you say **yes**, it will create its project files **alongside your files**.
* It wonâ€™t delete anything, but thereâ€™s a chance of **naming conflicts** (e.g., overwriting `index.html`).

âš ï¸ So, itâ€™s *safer* to run it in an **empty folder** (or one you donâ€™t mind being reorganized).

---

## ğŸ§© 3ï¸âƒ£ Ideal workflow

Hereâ€™s the clean, professional sequence:

```bash
# Step 1 â€” Create your frontend folder
mkdir frontend
cd frontend

# Step 2 â€” Create the vite project inside it
npm create vite@latest .

# Step 3 â€” Choose â€œVanillaâ€ (if you just want HTML, CSS, JS)
#          or â€œReactâ€, â€œVueâ€, etc. depending on what youâ€™re building.

# Step 4 â€” Install dependencies
npm install

# Step 5 â€” Run it
npm run dev
```

âœ… This will automatically generate `index.html`, link it to a `main.js`,
and set up everything ready for Tailwind or any frontend library.

---

## ğŸ§± 4ï¸âƒ£ If you already created your own HTML/CSS manually

No problem â€” you can still use Vite later.

In that case:

* Move your files (`index.html`, `style.css`, `script.js`) into the new Vite folderâ€™s structure.
* Then Vite will serve and build them for you.

Example:

```
frontend/
â”œâ”€â”€ index.html        â† your original HTML
â”œâ”€â”€ style.css         â† your original CSS
â”œâ”€â”€ main.js           â† created by Vite
â”œâ”€â”€ vite.config.js
â””â”€â”€ package.json
```

Just make sure your `<script>` in `index.html` points to `/main.js`.


*************************************************************************************************************************


After this stage, Vite creates /public folder and /src folder .gitignore index.html ts.config.json in the frontend folder.

*************************************************************************************************************************

âš™ï¸ 2ï¸âƒ£ What npm install actually does

When you run:

npm install


npm looks at your package.json, and:

Reads the list of dependencies (e.g. vite, typescript)

Downloads their exact versions (and their sub-dependencies) from the npm registry

Stores them in a folder called node_modules/

Generates a file called package-lock.json to record exact versions for reproducibility

âœ… After this, your folder will look like:

frontend/
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â”œâ”€â”€ package-lock.json
â”œâ”€â”€ vite.config.js
â”œâ”€â”€ node_modules/         â† All dependencies installed here
â””â”€â”€ src/


Now your project can actually run.

âš™ï¸ 3ï¸âƒ£ What gets installed (behind the scenes)

If you open package.json, everything under:

"devDependencies": { ... }


and

"dependencies": { ... }


is what npm installs.

For a simple Vite + TypeScript app, that means:

Package	Purpose
vite	The development server & bundler
typescript	TypeScript compiler and type-checking
@vitejs/plugin- (if any)*	Plugin to connect React/Vue/etc. with Vite
Any framework you selected (like react, vue, etc.)	Actual UI library youâ€™ll use

npm will also recursively install everything those depend on â€” hundreds of small packages under the hood that make Vite work (e.g. esbuild, postcss, rollup).

ğŸ§± 4ï¸âƒ£ Why itâ€™s necessary

Without npm install, your project only has metadata â€”
it knows what dependencies it needs, but doesnâ€™t have them yet.

So if you try to run:

npm run dev


youâ€™ll get:

Error: Cannot find module 'vite'


Because Vite isnâ€™t installed until npm install actually downloads it.

âš™ï¸ 5ï¸âƒ£ After installing â€” what happens next

Once installation completes, you can run:

npm run dev


âœ… That starts the Vite development server:

Local:   http://localhost:5173/
Network: http://192.168.x.x:5173/


And now your app will open in your browser â€” with hot reload, TypeScript support, and everything Vite offers.

*************************************************************************************************************************

In your package.json there are more details to add

under scripts, you need to specify how command like ***npm run start*** will work

You do that by adding a script

```js
  "scripts": {
    "start": "node server.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
```

also you should add the type: module, so you can use ES6 import syntax

```js
  "type": "module",
```

You can also add a script as a watcher to check when there are changed so you should install 
npm insall --sav-dev nodemon

the you add this script to package.json

```js
  "scripts": {
    "start": "node server.js",
    "dev": "node server.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
```

ğŸ§  1. What nodemon actually does

nodemon is a development tool that automatically restarts your Node.js app whenever you change a file (like server.js, a route, or controller).

Without it, you have to manually stop and restart Node every time you edit code.

So:

Tool	Behavior
node server.js	Runs the app once â€” no restarts on changes
nodemon server.js	Watches files and restarts automatically on save

Thatâ€™s why itâ€™s usually installed as a dev dependency:

npm install --save-dev nodemon

âš™ï¸ 2. "type": "module" â€” how it affects you

Since your package.json includes:

"type": "module"


youâ€™re using ES Modules (i.e., import/export syntax), not CommonJS (require()).

âœ… Good news: nodemon supports ES Modules perfectly fine.
You just need to make sure your script uses node normally, no extra flags required (Node 14+ handles it).

ğŸ§© 3. How to configure scripts correctly

Hereâ€™s the best practice setup for your package.json:

```js
{
  "type": "module",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  }
}
```

Explanation:

npm run start â†’ used in production. Runs your app once (no restarts).

npm run dev â†’ used during development. Automatically restarts on file changes.

ğŸ§  4. Why you need nodemon (and when you donâ€™t)
Environment	Should you use nodemon?	Why
Local development	âœ… Yes	Automatically reloads app when you save files
Production	âŒ No	Production apps should be managed by process managers like PM2 or systemd
CI/CD pipelines	âŒ No	Scripts run once, donâ€™t need watchers

So in your workflow:

Youâ€™ll typically run npm run dev while building or testing APIs locally.

Then when deploying (server, VPS, etc.), youâ€™ll use npm start â€” no nodemon.

âš™ï¸ 5. Optional: fine-tuning nodemon

You can customize what files it watches or restarts by adding a nodemon.json file:

```js
{
  "watch": ["server.js", "routes/", "controllers/"],
  "ext": "js,json",
  "ignore": ["node_modules"],
  "exec": "node server.js"
}
```

Thatâ€™s helpful if you have a big project and only want to restart when backend files change.

ğŸ§¾ 6. Without nodemon (manual alternative)

You can still use plain node â€” youâ€™ll just have to restart manually every time you edit:

node server.js
Itâ€™s fine for simple scripts, but gets annoying fast once you start editing routes or DB logic often.


*************************************************************************************************************************

If you want Nodemon to automatically load .env variables on restart (so you donâ€™t rely on dotenv inside your code):

Install dotenv-cli
:

npm install --save-dev dotenv-cli


Then update nodemon.json:

{
  "watch": ["server.js", "routes/", "controllers/"],
  "ext": "js,json",
  "ignore": ["node_modules"],
  "exec": "dotenv node server.js"
}


That way, it always loads .env variables when restarting.

b) Add a startup delay (if DB takes time)

```js
"delay": "500ms"
```

Sometimes helps if you have heavy DB connections and frequent restarts.


*************************************************************************************************************************


In the backend, install the needed dependencies
```js

  "dependencies": {
    "bcrypt": "^6.0.0",
    "dotenv": "^17.2.3",
    "fastify": "^5.6.1",
    "fastify-cookie": "^5.6.1",
    "fastify-cors": "^6.0.3",
    "fastify-multipart": "^5.3.1",
    "fastify-plugin": "^5.1.0",
    "fastify-static": "^4.6.1",
    "sqlite3": "^5.1.7"
  }
```

-----------------------------------------------------------------------------------------------------------------------------

Read more about other fastify modules in the ecosystem documentation here

https://fastify.dev/docs/v1.14.x/Documentation/Ecosystem/


-----------------------------------------------------------------------------------------------------------------------------
Why do we need all these fastify modules? 
Let's unravel them

Letâ€™s start with **`fastify-cookie`** (modern equivalent: `@fastify/cookie`).


## 1. What `fastify-cookie` does

In short:

> It adds **cookie support** to Fastify:
>
> * parses incoming `Cookie` headers â†’ `request.cookies`
> * lets you **set** cookies easily â†’ `reply.setCookie(...)`
> * supports **signed cookies** for integrity

Without it, Fastify does **not** parse cookies by default. Youâ€™d just see the raw `Cookie` header and would have to parse it manually.

Official docs describe it as: â€œA plugin to add cookies supportâ€ using an `onRequest` hook to parse cookies before your handlers run.

---

## 2. Why you need it

Most real apps end up needing cookies for:

* Authentication (session IDs, JWTs)
* â€œRemember meâ€
* CSRF tokens
* Locale / theme preferences
* Tracking/logged-in state between requests

---

## 3. How it works (with examples)

### Basic setup

```js
import Fastify from "fastify";
import cookie from "@fastify/cookie"; // or "fastify-cookie" in older code

const fastify = Fastify();

await fastify.register(cookie, {
	// optional: for signed cookies
	secret: "a-very-long-secret-key-change-me", 
  // the secret can be generated and stored in the .env
});

// you can then read all the cookies like this
fastify.get("/read", async (request, reply) => {
	// all cookies as an object
	console.log(request.cookies);
	return { cookies: request.cookies };
});

//you can also set a cookie with its maturity this way
fastify.get("/set", async (request, reply) => {
	reply
		.setCookie("theme", "dark", {
			httpOnly: true,
			path: "/",
			maxAge: 60 * 60 * 24 * 30, // 30 days
		})
		.send({ ok: true });
});

fastify.listen({ port: 3000 });
```

### Signed cookies

<!-- When you pass a `secret`, you can do: -->
```js
reply.setCookie("session", "user-123", {
	signed: true,
	httpOnly: true,
});

console.log(request.cookies.session);        // verified value or undefined
console.log(request.unsignCookie(...));      // low-level access
```

This ensures the client canâ€™t tamper with the cookie value without being detected.

---

## 4. Common use cases

Letâ€™s make this very concrete.

### a) Session IDs

You store the **session ID** in a cookie, actual session data in Redis/DB:

```js
fastify.get("/me", async (req, reply) => {
	const sid = req.cookies.sid;
	if (!sid) return reply.status(401).send({ error: "No session" });

	// lookup in DB
	const user = await getUserBySessionId(sid);
	if (!user) return reply.status(401).send({ error: "Invalid session" });

	return { id: user.id, email: user.email };
});
```

### 5.2 For sessions

If your goal is **sessions**, consider:

* `@fastify/secure-session` â€“ encrypted, stateless-style cookie-based sessions.
* `@fastify/session` â€“ classic server-side sessions.

Both rely on `@fastify/cookie` under the hood (or need cookie support), so cookie plugin is usually still in the stack.

If youâ€™re doing pure API + SPA:

* Use `Authorization: Bearer <token>` headers.
* No cookies at all.
* Then you donâ€™t need `fastify-cookie` unless you later add web-login flows.

-----------------------------------------------------------------------------------------------------------------------------

**`fastify-cors`** (or its modern equivalent `@fastify/cors`).

This is one of the *most misunderstood but absolutely essential* Fastify plugins â€” especially when your **frontend (React/Vue/Next)** is on a different port or domain from your **backend (Fastify)**.

---

## ğŸ§  1. What `fastify-cors` / `@fastify/cors` does

> It enables your Fastify server to handle **CORS** (Cross-Origin Resource Sharing) â€”
> a browser security mechanism that controls which origins (websites) can make requests to your backend API.

Without it, browsers **block** your frontendâ€™s fetch requests if they come from a different origin.

---

### ğŸ” What is â€œoriginâ€?

An **origin** = protocol + domain + port
(e.g. `https://myapp.com`, `http://localhost:5173`, etc.)

So if youâ€™re running:

* Frontend: `http://localhost:5173`
* Backend: `http://localhost:3000`

Then by default, browser JavaScript **cannot fetch** your Fastify API (because itâ€™s a different origin).

Thatâ€™s where `fastify-cors` comes in â€” it tells the browser:

> â€œItâ€™s safe to allow this external origin to access my server.â€

---

## âš™ï¸ 2. How it works

When you register the plugin:

```js
import Fastify from "fastify";
import cors from "@fastify/cors";

const fastify = Fastify();

// Enable CORS
await fastify.register(cors, {
	origin: "http://localhost:5173", // allow only this frontend
	credentials: true,               // allow cookies/auth headers
});
```

Fastify will now:

* Automatically add `Access-Control-Allow-Origin` headers to responses
* Handle `OPTIONS` preflight requests for complex methods (like `POST`, `PUT`, etc.)
* Optionally handle credentials (`Access-Control-Allow-Credentials`)

âœ… So now your frontend app can talk to your Fastify API freely.

---

## ğŸ§© 3. Typical use cases

Letâ€™s see how it applies in real-world scenarios ğŸ‘‡

---

### a) Local dev: frontend + backend on different ports

```js
fastify.register(cors, {
	origin: "http://localhost:5173",
});
```

â†’ allows your local React/Vue dev server to fetch from Fastify.

---

### b) Production: hosted frontend and backend

```js
fastify.register(cors, {
	origin: "https://myfrontend.com",
});
```

â†’ Only that specific domain can send requests.

---

### c) Multiple allowed origins

If you want to allow both local and production:

```js
const allowedOrigins = [
	"http://localhost:5173",
	"https://myfrontend.com",
];

fastify.register(cors, {
	origin: (origin, cb) => {
		if (!origin || allowedOrigins.includes(origin)) {
			cb(null, true);
		} else {
			cb(new Error("Not allowed by CORS"), false);
		}
	},
});
```

This lets you dynamically validate origins at runtime.

---

### d) Public API

If youâ€™re building a **public API** (no restrictions):

```js
fastify.register(cors, { origin: "*" });
```

âš ï¸ But be careful â€” this means *any* website can make requests.
Avoid this if your API has user data or requires authentication.


-----------------------------------------------------------------------------------------------------------------------------

## ğŸ§  1. What `fastify-multipart` does

> It lets Fastify handle **`multipart/form-data`** requests â€”
> the special kind of HTTP request browsers send when you upload files using a `<form>` or API like `FormData`.

Without it, Fastify only understands:

* `application/json` (for JSON bodies)
* `application/x-www-form-urlencoded` (for simple form fields)

If a request comes in with `multipart/form-data`, Fastify (by itself) wonâ€™t know how to read it â€”
youâ€™d just get a raw unreadable stream.

`fastify-multipart` parses that stream into easy-to-use **fields** and **file streams**.

---

## âš™ï¸ 2. How it works

Itâ€™s a **plugin** that adds special request decorators:

* `request.file()` â†’ to get a single uploaded file
* `request.files()` â†’ to handle multiple uploads
* `request.parts()` â†’ an async iterator over all form parts

It handles:

* parsing multipart boundaries
* file stream creation
* size limits
* temp storage or in-memory streaming

---

## ğŸ§© 3. Basic setup

```js
import Fastify from "fastify";
import multipart from "@fastify/multipart";

const fastify = Fastify();

await fastify.register(multipart, {
	limits: {
		fileSize: 10_000_000, // 10 MB max per file
	},
});

fastify.post("/upload", async function (req, reply) {
	const file = await req.file(); // one file expected
	const { filename, mimetype, file: stream } = file;

	await pump(stream, fs.createWriteStream(`./uploads/${filename}`));

	return { status: "uploaded", name: filename, type: mimetype };
});

fastify.listen({ port: 3000 });
```

Here we used `req.file()` to handle one file.

`pump()` is a safe utility from the `pump` package for connecting readable â†’ writable streams.

---

## ğŸ§  4. Real-world use cases

Letâ€™s see where youâ€™ll commonly need it ğŸ‘‡

---

### a) ğŸ–¼ Uploading profile images

Frontend sends:

```js
const form = new FormData();
form.append("avatar", fileInput.files[0]);

await fetch("/upload", {
	method: "POST",
	body: form,
});
```

Backend route:

```js
fastify.post("/upload", async (req, reply) => {
	const data = await req.file();
	const filename = `avatar_${Date.now()}_${data.filename}`;
	await pump(data.file, fs.createWriteStream(`./uploads/${filename}`));
	return { success: true, path: `/uploads/${filename}` };
});
```

---

### b) ğŸ“ Uploading multiple files

Frontend:

```js
const form = new FormData();
for (const file of files) form.append("docs", file);
await fetch("/multi", { method: "POST", body: form });
```

Backend:

```js
fastify.post("/multi", async (req, reply) => {
	const parts = req.parts();
	for await (const part of parts) {
		if (part.file) {
			const dest = fs.createWriteStream(`./uploads/${part.filename}`);
			await pump(part.file, dest);
		}
	}
	return { uploaded: true };
});
```

---

### c) ğŸ§¾ Upload + metadata (mixed form fields)

HTML form might include both file(s) and other data (like title, description).

You can access text fields via:

```js
const data = await req.file();
console.log(data.fields); // { title: "My document" }
```

Or iterate manually and handle parts differently based on whether they have `.file`.

---

### d) ğŸ§° Stream processing (no file saving)

You can also *stream* directly to a cloud service instead of saving locally:

```js
import { S3Client, PutObjectCommand } from "@aws-sdk/client-s3";

fastify.post("/upload", async (req, reply) => {
	const file = await req.file();
	const params = {
		Bucket: "my-bucket",
		Key: file.filename,
		Body: file.file,
		ContentType: file.mimetype,
	};
	await s3.send(new PutObjectCommand(params));
	return { ok: true };
});
```

This avoids ever writing to disk â€” perfect for serverless deployments.

---

## âš–ï¸ 5. Why you need it

Without `fastify-multipart`, the uploaded file would be a **raw binary stream** under `req.raw`,
and youâ€™d have to parse multipart boundaries manually â€” which is tedious and error-prone.

`fastify-multipart` gives you:
âœ… automatic parsing
âœ… safe file limits
âœ… backpressure-aware streaming
âœ… simple API for files & fields

---

## ğŸ§± 6. Options and configuration

Common config fields:

```js
fastify.register(multipart, {
	addToBody: true, // parse non-file fields into req.body
	limits: {
		fieldNameSize: 100,   // max field name length
		fieldSize: 1000000,   // max field value size
		files: 2,             // max number of files
		fileSize: 10_000_000, // per-file limit
	},
	onFile: async (part) => {
		// optional global handler
		await pump(part.file, fs.createWriteStream(`./uploads/${part.filename}`));
	},
});
```

-----------------------------------------------------------------------------------------------------------------------------


##  What `fastify-plugin` does

> `fastify-plugin` is used to **turn a normal function into a reusable Fastify plugin**.
> It tells Fastify:
> â€œThis code is a *plugin* â€” donâ€™t encapsulate it, and make its decorations and hooks available globally (if registered globally).â€

In simpler words:

> Itâ€™s how you **package reusable logic** (like DB connections, utilities, or routes) so you can use them cleanly across your app or even publish them to npm.

---

## âš™ï¸ 2. Why you need it

When you just register a function like this:

```js
fastify.register(async (fastify) => {
	fastify.decorate("db", myDb);
});
```

Fastify will encapsulate that registration.
That means â€” any `fastify.decorate`, hooks, or routes inside are **only available inside that pluginâ€™s scope**, not in the rest of your app.

Thatâ€™s called **encapsulation**, and itâ€™s part of Fastifyâ€™s design for safety and modularity.

However â€” sometimes you **do want** those decorations (like your DB instance) to be available globally.

Thatâ€™s where `fastify-plugin` comes in.

---

## ğŸ”§ 3. Basic example

### Without `fastify-plugin`

```js
// db.js
export async function dbConnector(fastify) {
	const db = await connectToDatabase();
	fastify.decorate("db", db);
}
```

### Main file

```js
import Fastify from "fastify";
import { dbConnector } from "./db.js";

const fastify = Fastify();
await fastify.register(dbConnector);

fastify.get("/", async (req, reply) => {
	console.log(fastify.db); // âŒ undefined (encapsulated)
});
```

### âœ… With `fastify-plugin`

```js
// db.js
import fp from "fastify-plugin";

async function dbConnector(fastify) {
	const db = await connectToDatabase();
	fastify.decorate("db", db);
}

export default fp(dbConnector);
```

Now:

```js
import Fastify from "fastify";
import dbPlugin from "./db.js";

const fastify = Fastify();
await fastify.register(dbPlugin);

fastify.get("/", async (req, reply) => {
	console.log(fastify.db); // âœ… works everywhere
});
```

So `fastify-plugin` removes the encapsulation boundary for that plugin â€” its decorations become visible to the rest of the app.

---

## ğŸ§© 4. Why encapsulation exists

Encapsulation in Fastify means each plugin has its **own isolated context** â€” its own set of routes, hooks, and decorations.

This is great for:

* building independent modules
* avoiding accidental interference
* testing plugins in isolation

But sometimes, you need shared state (like a database connection, utility, or auth decorator) â€” thatâ€™s when you use `fastify-plugin`.


-----------------------------------------------------------------------------------------------------------------------------

ğŸ”¥ Excellent â€” now weâ€™re at the last core one: **`fastify-static`** (or in modern Fastify, `@fastify/static`).

This plugin powers one of the most common things a backend does:

> Serving static assets like images, uploaded files, or even your entire frontend build (React, Vue, Svelte, etc.) directly from your Fastify server.

Letâ€™s go deep step-by-step ğŸ‘‡

---

## ğŸ§  1. What `fastify-static` does

> It lets your Fastify app **serve static files** (HTML, CSS, JS, images, PDFs, etc.) from a local folder via HTTP.

Think of it as Fastifyâ€™s version of Expressâ€™s `express.static()` middleware.
Without it, Fastify only handles **dynamic routes** â€” it wonâ€™t automatically serve files from disk.

So `fastify-static` adds an efficient static file server built on Nodeâ€™s `fs` streams and `send` library.

---

## âš™ï¸ 2. Basic setup

Letâ€™s start simple.

```js
import Fastify from "fastify";
import fastifyStatic from "@fastify/static";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const fastify = Fastify();

// Serve files from ./public folder
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "public"),
	prefix: "/public/", // optional URL prefix
});

fastify.listen({ port: 3000 });
```

âœ… Now if you have:

```
public/
 â”œâ”€ logo.png
 â”œâ”€ index.html
 â””â”€ css/style.css
```

You can access them directly:

```
http://localhost:3000/public/logo.png
http://localhost:3000/public/css/style.css
```

---

## ğŸ§© 3. Real-world use cases

Letâ€™s look at several **practical scenarios** ğŸ‘‡

---

### a) ğŸ’» Serving your frontend build (React, Vue, etc.)

When you build your frontend, you usually get something like:

```
frontend/dist/
 â”œâ”€ index.html
 â”œâ”€ assets/
 â”œâ”€ bundle.js
```

You can serve it via:

```js
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "../frontend/dist"),
});
```

Then visiting `http://localhost:3000` loads your SPA.
(You might also add a fallback route to send `index.html` for all unknown paths â€” see below.)

---

### b) ğŸ“¸ Serving user-uploaded files

If youâ€™re using `fastify-multipart` to upload files to `./uploads`,
you can expose them with:

```js
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "uploads"),
	prefix: "/uploads/", // accessible under /uploads/
});
```

Now an uploaded image saved as `uploads/123.png` is accessible at:

```
http://localhost:3000/uploads/123.png
```

This is perfect for profile pictures, documents, and attachments.

---

### c) ğŸ“ Serving multiple directories

You can register multiple static directories if needed:

```js
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "public"),
	prefix: "/public/",
});

fastify.register(fastifyStatic, {
	root: path.join(__dirname, "uploads"),
	prefix: "/uploads/",
});
```

So `/public` and `/uploads` serve separate folders.

---

### d) âš™ï¸ Fallback route for SPAs

Single Page Apps (React Router, Vue Router, etc.) need the **same index.html** for all routes (e.g. `/about`, `/dashboard`).

Add this after your static registration:

```js
fastify.setNotFoundHandler((req, reply) => {
	if (req.raw.url.startsWith("/api")) {
		reply.code(404).send({ error: "Not found" });
	} else {
		reply.sendFile("index.html"); // serve SPA
	}
});
```

Now `/dashboard` or `/settings` will render your app.

---

## âš¡ 4. Options explained

```js
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "public"),
	prefix: "/assets/",           // default: '/'
	decorateReply: true,          // adds reply.sendFile()
	serveDotFiles: false,         // ignore hidden files (like .env)
	cacheControl: true,           // adds cache headers
	maxAge: "1d",                 // caching duration
});
```

* **`root`** â†’ Folder path to serve files from.
* **`prefix`** â†’ URL prefix (optional).
* **`decorateReply`** â†’ Adds `reply.sendFile(filename)` helper.
* **`cacheControl`, `maxAge`** â†’ Control browser caching.
* **`serveDotFiles`** â†’ Protect hidden files like `.env`.

---

## ğŸ’¡ 5. Using `reply.sendFile()`

When `decorateReply` is true (default), Fastify adds a shortcut:

```js
fastify.get("/", (req, reply) => {
	reply.sendFile("index.html"); // automatically looks in root
});
```

Thatâ€™s super handy for fallback routes or conditional responses.

---

## âš™ï¸ 6. Example: Full backend + frontend integration

```js
import Fastify from "fastify";
import fastifyStatic from "@fastify/static";
import path from "path";
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

const fastify = Fastify({ logger: true });

// Serve React build
fastify.register(fastifyStatic, {
	root: path.join(__dirname, "../client/dist"),
	prefix: "/", // serve at root
});

// API routes
fastify.get("/api/hello", async () => ({ msg: "Hello from API" }));

// Fallback to SPA
fastify.setNotFoundHandler((req, reply) => {
	if (!req.raw.url.startsWith("/api")) {
		reply.sendFile("index.html");
	} else {
		reply.code(404).send({ error: "Not found" });
	}
});

fastify.listen({ port: 3000 });
```

Now:

* `/api/hello` â†’ Fastify route
* `/` or `/dashboard` â†’ React app served from dist

Perfect for full-stack apps ğŸš€

---

## ğŸ§¾ 7. Why we need it

Without this plugin:

* Fastify doesnâ€™t serve files at all â€” only responds to defined routes.
* Youâ€™d have to manually use `fs.createReadStream()` to send files, which is inefficient.
* Youâ€™d lose built-in caching, MIME type detection, and range support (for media).

With `fastify-static`, you get all that automatically.


-----------------------------------------------------------------------------------------------------------------------------

*************************************************************************************************************************


The next step now is to create a server.js file in the backend, and configure it

the fastify documentation gives a nice guide

https://www.npmjs.com/package/fastify?activeTab=readme

// Require the framework and instantiate it
// CommonJs
const fastify = require('fastify')({
  logger: true
})

// Declare a route
fastify.get('/', (request, reply) => {
  reply.send({ hello: 'world' })
})

// Run the server!
fastify.listen({ port: 3000 }, (err, address) => {
  if (err) throw err
  // Server is now listening on ${address}
})


*************************************************************************************************************************

After this, here are the net steps

| Step  | Task                                        | Why / Goal                                               |
| ----- | ------------------------------------------- | -------------------------------------------------------- |
| **1** | ğŸŸ© Add `.env` and `dotenv` to backend       | For config management (port, DB path, secrets, etc.)     |
| **2** | ğŸŸ© Add SQLite (database connection)         | To start storing real data (users, posts, etc.)          |
| **3** | ğŸŸ© Connect frontend to backend (via fetch)  | To test API calls from your frontend                     |
| **4** | ğŸŸ¨ Configure Nginx                          | Only *after* both backend & frontend run well separately |
| **5** | ğŸŸ§ Dockerize all (frontend, backend, nginx) | Optional final deployment step                           |


*************************************************************************************************************************


### DOTENV

https://www.npmjs.com/package/dotenv

As early as possible in your application, import and configure dotenv:
It is a great plus to mention that your env file should never be pushed into public repo. So you should add a .env to gitignore so it is not pushed, and a standrad practice is to create a .env.example file that lists the key that are needed in the env files without the values.


*************************************************************************************************************************
### DATABASE

mkdir data
touch data/database.sqlite3

we can create a seperate file to setup the database, we will call this file, ***db.js*** in the our backend.

in db.js file, we will design how our created databse will work. How kt will creat tables on initialization.

we will need to import somethings inside this file

```js
import sqlite3 from 'sqlite3'
import fs from 'node.fs'
import path from 'path'
import { fileURLToPath } from "url";
```

why do we need to import these libraries or modules. many people just import sqlite3 and it works. To be candid, in production if not all imports are well added somthign can break. 

ğŸ§  1. fs â€” the File System module
To work with files and folders on your computer.
When setting up a database (like SQLite), you might need to:
Check if a folder exists before creating or opening the database file.
Create a directory for your database if it doesnâ€™t exist.
Read or write initialization SQL scripts (schema.sql, seed.sql, etc.).

Example:

```js
import fs from "node:fs";

const dbFolder = "./backend/data";

// if folder doesn't exist, create it
if (!fs.existsSync(dbFolder)) {
	fs.mkdirSync(dbFolder, { recursive: true });
}
```
Without fs, you couldnâ€™t safely create or verify that folder before connecting to your SQLite file.
The caveat is that, SQLite automatically creates the .sqlite file for you if the directory exists â€” but it cannot create the folder itself.


ğŸ§­ 2. path â€” for safe file paths
Purpose: To create and manage file paths that work on any operating system (Windows, macOS, Linux).
For example:

```js
import path from "path";
const dbPath = path.join(process.cwd(), "backend", "data", "db.sqlite");
```
This ensures your path separators (/ or \) are correct regardless of OS.

Using path (and optionally fileURLToPath) ensures your database path is always absolute, based on the fileâ€™s own location â€” not on where the process was started. Now no matter where you run your code â€” node backend/app.js, npm start, pm2, or vercel â€”
your database path will always resolve correctly.

Once you correctly use both of these:

```js
import path from "path";
import { fileURLToPath } from "url";
```

and then set your path like this:

```js
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
```

then âœ… Node.js will always locate your database file correctly, no matter where or how your app is executed.


Lets, dive deep

## ğŸ§© Line 1:

```js
const __filename = fileURLToPath(import.meta.url);
```

### ğŸ§  Whatâ€™s going on here:

In CommonJS (the old Node.js module system), we always had two global variables available:

```js
__filename // gives the current fileâ€™s full path
__dirname  // gives the current directory path
```

But when Node.js introduced **ES Modules** (using `import`/`export`),
those two no longer exist automatically. âŒ

So we need to **recreate them manually**.

---

### ğŸ” Breaking down this line

#### ğŸ§± `import.meta.url`

* This gives the **URL of the current module**.
* For a local file, it looks like this:

  ```
  file:///Users/abdulazeez/projects/backend/database.js
  ```

#### âš™ï¸ `fileURLToPath(import.meta.url)`

* This converts that `file:///` URL into a **real file system path**.
* The result will look like:

  ```
  /Users/abdulazeez/projects/backend/database.js
  ```

#### ğŸª„ Assign it:

```js
const __filename = fileURLToPath(import.meta.url);
```

So now youâ€™ve recreated the **absolute path** to your current file â€” just like old `__filename`.

---

### âœ… Example result

If your file is:

```
/home/abdulazeez/myapp/src/database.js
```

then:

```js
console.log(__filename);
```

prints:

```
/home/abdulazeez/myapp/src/database.js
```

---

## ğŸ§© Line 2:

```js
const __dirname = path.dirname(__filename);
```

### ğŸ§  Whatâ€™s happening:

* You already have the file path (`__filename`).
* `path.dirname()` takes a full file path and **returns the folder itâ€™s inside**.

So from:

```
/home/abdulazeez/myapp/src/database.js
```

it gives you:

```
/home/abdulazeez/myapp/src
```

Now you have your **directory path** â€” thatâ€™s your recreated `__dirname`.

---

### âœ… Example

```js
console.log(__dirname);
```

â¡ï¸ `/home/abdulazeez/myapp/src`

You can now safely use this with `path.join()`:

```js
const dbPath = path.join(__dirname, "data", "db.sqlite");
```

â¡ï¸ `/home/abdulazeez/myapp/src/data/db.sqlite`


*************************************************************************************************************************
After we have done these imports, we have to noe create a function that we will use to setup the database using fastify

we say 
```js
function setupDb(fastify){
  //we declare the database directory here, and confirm if it is present.
  const dbDir = path.resolve(__dirname, "data")

  // if this directory exists before we continue, otherwise we create it and use recursive:true to create every other directory needed to lead it it
  if(!fs.existsSync(dbDir)) {
    fs.mkdirSync(dbDir, {recursive: true});
  }
}
```

Letâ€™s explain both parts of ***sync*** and ***recursive: true*** in detail:

### ğŸ‘‰ `Sync` methods

### ğŸ‘‰ `recursive: true`

---

## ğŸ§  1. What the **`Sync`** means

When you see `fs.existsSync()` or `fs.mkdirSync()`, that **Sync** means **synchronous** â€” i.e. the operation *blocks* the program until it finishes.

So in your example:

```js
if (!fs.existsSync(dbDir)) {
	fs.mkdirSync(dbDir, { recursive: true });
}
```

this code says:

> â€œBefore going any further, check if this folder exists â€” and if not, create it.
> Wait until itâ€™s done before continuing.â€

Thatâ€™s it.

---

### ğŸ’¡ Why use the Sync version here

Creating or checking a folder is a **tiny, one-time** operation that happens **before** your server or database starts running.

You donâ€™t need to make it asynchronous because:

* It only runs once.
* It finishes almost instantly.
* It simplifies the logic (no callback or Promise needed).

So itâ€™s perfectly fine â€” even ideal â€” to use the synchronous (`Sync`) version here.

---

### âš ï¸ When *not* to use Sync

If you were doing something that happens **many times**, or **could take a while** (like reading lots of files in a web server request),
then youâ€™d prefer the asynchronous version:

```js
fs.exists(dbDir, (exists) => {
	if (!exists) {
		fs.mkdir(dbDir, { recursive: true }, (err) => {
			if (err) console.error(err);
		});
	}
});
```

But for setup scripts, startup configuration, or one-time initialization â†’ synchronous is clean and safe âœ…

---

## ğŸ§© 2. What **`recursive: true`** means

This option tells Node.js:

> â€œIf the parent directories donâ€™t exist, create them too.â€

Example:

```js
fs.mkdirSync("backend/data/db", { recursive: true });
```

### Without `recursive: true`:

* If `backend/` exists but `backend/data/` doesnâ€™t â†’ âŒ Error (`ENOENT`).
* Youâ€™d have to create each folder manually.

### With `recursive: true`:

* Node will **automatically create all missing parent folders** along the path.
* So even if `backend/` or `data/` didnâ€™t exist, itâ€™ll make them for you.
* No errors, just quietly ensures the whole path exists âœ…

*************************************************************************************************************************

Let's proceed

```js

import sqlite3 from 'sqlite3'
import fs from 'node.fs'
import path from 'path'
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename)

function setupDb(fastify){
  //we declare the database directory here, and confirm if it is present.
  const dbDir = path.resolve(__dirname, "data")

  // if this directory exists before we continue, otherwise we create it and use recursive:true to create every other directory needed to lead it it
  if(!fs.existsSync(dbDir)) {
    fs.mkdirSync(dbDir, {recursive: true});
  }

  // now we are sure our dbDir is present, so we can now do somethign similar with out dbpath

  const dbPath = path.join(dbDir, "db.sqlite")

}
```
you should ask a question, â€œIf we create the folder when missing, why donâ€™t we also create the file when missing?â€
Node.js (and the OS) will not automatically create missing folders. So if ./backend/data/ doesnâ€™t exist, you must create it yourself, But SQLite will automatically create the .sqlite database file when you connect to it, if it doesnâ€™t exist.

So lets proceed
From here we Connect to (or create) the SQLite database

```js

import sqlite3 from 'sqlite3'
import fs from 'node.fs'
import path from 'path'
import { fileURLToPath } from "url";

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename)

export function setupDb(fastify){
  const dbDir = path.resolve(__dirname, "data")
  if(!fs.existsSync(dbDir)) {
    fs.mkdirSync(dbDir, {recursive: true});
  }
  const dbPath = path.join(dbDir, "db.sqlite")

  //connect or create the database

  const db = new sqlite3.Databse(dbPath, (err) => {
    if (err) {
      console.error("Error creating database: " err.message);
      return;
    }

    // if we dont have error, then it means database was created

    console.log("Database connected successfully");

    // now wr do db.run to creaete all the table we need and their respective columns
    db.run(
      `CREATE TABLE IF NOT EXISTS players (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        username TEXT NOT NULL UNIQUE,
        email TEXT NOT NULL UNIQUE,
        password TEXT NOT NULL,
        wins INTEGER DEFAULT 0,
        losses INTEGER DEFAULT 0,
        avatar TEXT DEFAULT 'avatar.png',
        preferred_language TEXT DEFAULT 'en',
        social_features_enabled BOOLEAN DEFAULT 1
      )`
    );

    db.run(
      `CREATE TABLE IF NOT EXISTS sessions (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        user_id INTEGER NOT NULL,
        token TEXT NOT NULL UNIQUE,
        created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
        FOREIGN KEY(user_id) REFERENCES players(id) ON DELETE CASCADE
      )`
    )
  })
  fastify.decorate("saliteDb", db);
}
```

***Question:***

```js
fastify.decorate("sqliteDb", db);
```

---

## ğŸ§  1. What `fastify.decorate()` does

`decorate()` is a **Fastify API** method used to **add custom properties or functions** to the Fastify instance.

In plain English:

> It lets you â€œattachâ€ extra tools or data (like a database connection) to the Fastify server object,
> so you can access them anywhere in your routes, hooks, or plugins.

---

### ğŸ§© Example conceptually

If you write:

```js
fastify.decorate("hello", "world");
```

Then anywhere in your app (like a route):

```js
fastify.get("/", async (request, reply) => {
	return fastify.hello; // "world"
});
```

You can think of it like:

> `fastify.hello = "world"`

But itâ€™s done through Fastifyâ€™s internal plugin system â€” which is safer, scoped, and extendable.

---

## ğŸ§± 2. In your case

```js
fastify.decorate("sqliteDb", db);
```

means:

> â€œAdd a property named `sqliteDb` to the Fastify instance,
> and set its value to my SQLite database connection (`db`).â€

---

### So if you have:

```js
const db = new sqlite3.Database(dbPath);
fastify.decorate("sqliteDb", db);
```

Then later, in any route:

```js
fastify.get("/items", (req, reply) => {
	fastify.sqliteDb.all("SELECT * FROM items", (err, rows) => {
		if (err) reply.send(err);
		else reply.send(rows);
	});
});
```

âœ… You can use the same database connection (`db`) everywhere without re-importing or recreating it.

---

## ğŸ§© 3. Where the argument `sqliteDb` comes from

Thatâ€™s just the **name you choose** for your decoration â€” it doesnâ€™t exist beforehand.

Itâ€™s the *key* that you define when decorating Fastify.

In this code:

```js
fastify.decorate("sqliteDb", db);
```

* `"sqliteDb"` â†’ the name/key you want to attach to the Fastify instance.
* `db` â†’ the **actual object or value** youâ€™re attaching (the SQLite connection).

You could call it anything:

```js
fastify.decorate("database", db);
```

and later access it with:

```js
fastify.database.all("SELECT * FROM items");
```

So the name is fully customizable â€” `sqliteDb` is just a developer choice.

---

## âš™ï¸ 4. Why we use `decorate()` instead of plain assignment

You *could* technically do:

```js
fastify.db = db;
```

But `fastify.decorate()` is **the official, safe way** because:

* It integrates with Fastifyâ€™s plugin system.
* It prevents accidental overwrites.
* It can be scoped to specific plugins.
* It works with encapsulation (so decorators in one plugin donâ€™t leak into others unless intended).

*************************************************************************************************************************

after creating this database js, we want to import it into our server

we also import ***path*** and ***fileURLToPath***
then we also import all the fastify modules which we have installed




*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************
*************************************************************************************************************************

### DOCKER


Then
âœ… Containerize all three and run them together using **Docker Compose** (so they can talk to each other like a real app).

---

# ğŸ§© STEP-BY-STEP WORKFLOW

---

## **1ï¸âƒ£ Install Docker (and Docker Compose)**

Before anything else:

* Install Docker Desktop (on Windows/Mac) or `docker` + `docker-compose` (on Linux).
* Verify with:

```bash
docker --version
docker compose version
```

âœ… Once Docker is installed and running, you can build and run containers from anywhere.

---

## **2ï¸âƒ£ Create `Dockerfile` in each folder**

Ideally, the file should be names, "Dockerfile" with a capitalized "D", but in the documentation, they allow a fallback for a small case starting "d".

So, go into the frontend folder, and create a file called "Dockerfile"

```Dockerfile
FROM node:20-alpine AS builder
WORKDIR /app
COPY frontend/package*.json ./
RUN npm install
COPY frontend ./
RUN npm run build
```

(this is like when you download a file, and you move to its folder, then you install all it needs to run)

what do they all mean?

FROM means: start with a base image (a prebuilt environment).
Here, we use Node.js v20 as our build environment.
AS builder names this stage â€” weâ€™ll refer to it later when we copy the built files in the nginx's dockerfile.

ğŸ‘‰ Itâ€™s like saying:
â€œStart a fresh container that already has Node.js installed, and call it builder.â€


WORKDIR /app
Sets the working directory inside the container.
All following commands will run inside /app.
If /app directory doesnâ€™t exist, Docker creates it.

COPY package*.json ./
Copies your package.json and package-lock.json (or yarn.lock) files into the container.
This ensures Docker knows what dependencies to install.

RUN npm install
Runs npm install inside the container.
Installs all dependencies listed in package.json.

âœ… After this step, all dependencies are inside the container â€” no need for a local node_modules.

COPY . .
Copies all the rest of your project files (source code, assets, etc.) from your machine into the containerâ€™s /app directory.

RUN npm run build
Runs your frontend build script (like vite build or react-scripts build).
Produces optimized static files (e.g., inside /app/dist or /app/build).

These are the files your web server will serve to users.


Now let us also create the Docker file for the backend

```Dockerfile
FROM node:20
WORKDIR /app
RUN apt-get update && apt-get install -y sqlite3 libsqlite3-dev
RUN groupadd -r appuser && useradd -r -g appuser appuser
COPY package.json package-lock.json ./
RUN npm ci
COPY . .
RUN chown -R appuser:appuser /app
USER appuser
EXPOSE 3000
CMD ["node", "server.js"]
```

## âš™ï¸ Line-by-line Explanation

---

### ğŸŸ¦ `FROM node:20`

* This sets your **base image**.
* Youâ€™re starting from the **official Node.js v20** Docker image.
* It already comes with Node and npm installed.

âœ… This means you donâ€™t need to manually install Node or npm â€” just use it right away.

---

### ğŸŸ¨ `WORKDIR /app`

* Sets `/app` as the **working directory** inside the container.
* All subsequent commands (`COPY`, `RUN`, etc.) will happen inside `/app`.
* If `/app` doesnâ€™t exist, Docker creates it automatically.

âœ… Equivalent to doing `cd /app` before running the next commands.

---

### ğŸŸ© `RUN apt-get update && apt-get install -y sqlite3 libsqlite3-dev`

* Installs **SQLite3** and its development libraries.
* `apt-get update` refreshes the package list.
* `apt-get install -y` installs the packages without asking for confirmation (`-y` = yes).

âœ… Youâ€™re doing this because your app likely uses a **SQLite database**, and Node needs the native SQLite libraries available inside the container.

---

### ğŸŸ§ `RUN groupadd -r appuser && useradd -r -g appuser appuser`

* Creates a **non-root user** (`appuser`) and group.
* `-r` = system user (no home directory, meant for services).
* `-g appuser` assigns the user to the group.

âœ… Security best practice:
You donâ€™t want your Node app running as **root** inside the container â€” this command sets up a safe user account that will later run the app.

---

### ğŸŸ¦ `COPY package.json package-lock.json ./`

* Copies only your dependency files first (not the entire project).
* This allows Docker to **cache** your dependencies between builds, improving speed.
  (If your source code changes but your dependencies donâ€™t, Docker skips reinstalling npm packages.)

âœ… Best practice for Docker layer caching.

---

### ğŸŸ¨ `RUN npm ci`

* Runs `npm ci` instead of `npm install`.
* `npm ci` = **clean install** based on your `package-lock.json` â€” it installs exact dependency versions, faster and more reliable for production.

âœ… Great choice â€” guarantees consistent builds.

---

### ğŸŸ© `COPY . .`

* Copies all your remaining source files (Fastify app, routes, configs, etc.) from your local folder to the containerâ€™s `/app`.

âœ… Now your appâ€™s code exists inside the container.

---

### ğŸŸ§ `RUN chown -R appuser:appuser /app`

* Changes ownership of the `/app` directory to your `appuser` user and group.
* Ensures the non-root user you created has permission to read/write inside `/app`.

âœ… Prevents permission errors later when the container runs as `appuser`.

---

### ğŸŸ¦ `USER appuser`

* Switches from the default root user to the safer `appuser` you created earlier.

âœ… From this line onward, all commands (including running Node) will execute as this non-root user â€” improving container security.

---

### ğŸŸ¨ `EXPOSE 3000`

* Declares that the app inside this container **listens on port 3000**.
* It doesnâ€™t open the port to your host â€” itâ€™s just documentation and helps Docker Compose link containers.

âœ… In your `docker-compose.yml`, youâ€™ll later map it like:

```yaml
ports:
  - "3000:3000"
```

or Nginx will proxy to `http://backend:3000`.

---

### ğŸŸ© `CMD ["node", "server.js"]`

* Defines the **default command** that runs when the container starts.
* It runs your Fastify (or Express) server.

âœ… Equivalent to typing `node server.js` in your terminal, but Docker runs it automatically when the container starts.

---


Now, Let us create our server Docker file

```Dockerfile
FROM nginx:stable

#before we copy anything we should install openssl hat provides a cryptographic library implementing the SSL/TLS protocols. It is widely used to secure internet communications by encrypting data between a server and a browser, and it includes tools for generating private keys, creating certificates, and other cryptographic functions

RUN apt-get update && apt-get install -y openssl && rm -rf /var/lib/apt/lists/*
RUN mkdir /etc/nginx/ssl
COPY nginx/nginx.conf /etc/nginx/conf.d/default.conf
COPY nginx/generate-cert.sh /docker-entrypoint.d/generate-cert.sh
RUN chmod +x /docker-entrypoint.d/generate-cert.sh
COPY --from=builder /app/dist /usr/share/nginx/html

---

What is happening here?

Now you switch to a clean **Nginx** environment to serve the static frontend files.

```dockerfile
FROM nginx:stable
```

* Starts from the official Nginx image.
* This image is smaller and faster than Node â€” perfect for serving built static files.
* Itâ€™s also more secure, because it doesnâ€™t include npm or dev tools.

---

```dockerfile
RUN apt-get update && apt-get install -y openssl && rm -rf /var/lib/apt/lists/*
```

* Installs **OpenSSL** so that the container can generate SSL/TLS certificates (for HTTPS).
* Then removes the package cache to keep the image small.

---

```dockerfile
RUN mkdir -p /etc/nginx/ssl
```

* Creates a directory where SSL certificates will be stored.

---

```dockerfile
COPY nginx/nginx.conf /etc/nginx/conf.d/default.conf
```

* Copies your custom **nginx.conf** from your project into the container.
* This file defines how Nginx routes traffic â€” for example, serving `/index.html` or proxying `/api` to your backend.

---

```dockerfile
COPY nginx/generate-cert.sh /docker-entrypoint.d/generate-cert.sh
RUN chmod +x /docker-entrypoint.d/generate-cert.sh
```

* Copies a **shell script** that automatically generates self-signed SSL certificates each time the container starts.
* Puts it in `/docker-entrypoint.d/`, a special folder Nginx runs automatically when starting up.
* `chmod +x` makes it executable.

âœ… This means HTTPS certificates are created dynamically â€” no manual setup needed.

---

```dockerfile
COPY --from=builder /app/dist /usr/share/nginx/html
```

* **This is the key line connecting the two stages.**
* It copies the built frontend files from the **builder stage** (`/app/dist`) into Nginxâ€™s default web root (`/usr/share/nginx/html`).
* Nginx then serves these files directly when users access the site.
